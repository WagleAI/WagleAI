# WagleAI

## Introduction
YOLOv3 딥러닝 모델을 활용하여 한국의 거리 밀집도를 실시간으로 분석하고  
분석된 정보를 사용자에게 시각화하여 제공할 수 있는 오픈소스 소프트웨어입니다.

## Installing
### 1. 가상환경 설정
기본적인 실행하기 위한 과정은 다음과 같습니다.
```bash
conda create --name yolo3 python=3.7
```
### 2. 시스템 환경 설정
동작을 위해 cuda 10.0, cudnn 7.6.5, tensorflow(-gpu) 1.15.0 버전은 반드시 맞춰주세요.  
패키지들의 설치를 위해 다음 명령어를 실행해 주세요.
```bash
pip install -r requirements.txt
```

## Detection
### 1. Pre-trained model 다운로드
사람을 단일 클래스로 학습한 모델 파일은 다음 링크에서 받으실 수 있습니다.  
<a>https://drive.google.com/file/d/11d08K8r7hgqcTD-jMRbGl7lao00OlzM7/view?usp=sharing</a>  

### 2. predict 실행
Detection 하기 위한 이미지나 동영상 파일을 프로젝트의 하위 폴더에 위치시킨 뒤 다음 명령어를 입력해 주세요.  
웹캠으로 탐지할 경우 -i 명령어에 webcam을, 동영상 파일로 탐지할 경우 저장되어있는 동영상들의 경로를 표시한 txt 파일의 경로를 입력합니다.  
여러 동영상들을 재생할 경우, 저장된 동영상의 개수에 맞게 txt 파일이 작성되었는지 확인해주세요.
```bash
python wagle.py --mode predict -c json파일의_경로 -i webcam/동영상_파일의_경로.txt -o 결과가 저장될 폴더 경로 --host 로그서버의 IP주소
```
탐지 결과는 ```output```폴더에 저장됩니다.

## Training
### 1. 데이터 준비
본 모델을 학습하기 위해 다음과 같은 데이터셋을 사용하였습니다.  
```
인도보행영상 : http://www.aihub.or.kr/aidata/136  
Multiple Object Tracking Benchmark : https://motchallenge.net  
```
파일 구조는 다음과 같이 설정해주세요
```
.
+-- data
|   +-- MOT
|   |   +-- MOT16
|   |   |   +-- test
|   |   |   +-- train
|   |   +-- MOT20
|   |   |   +-- test
|   |   |   +-- train
|   +-- Pedestrian
|   |   +-- Bbox_#
|   |   +-- Bbox_#
```
MOT데이터를 활용해 train/valid 폴더를 분리할 경우 다음 명령어를 입력해주세요.
```bash
python wagle.py --mode dataset -p ./data/MOT -m True -t data/train -v data/valid
```
보행자 데이터를 활용해 train/test 폴더를 분리할 경우 다음 명령어를 입력해주세요.
```bash
python wagle.py --mode dataset -p ./data/Pedestrian -m False, -t data/train -v data/valid
```
### 2. config_.json파일 수정하기
zoo 폴더 하위에 위치한 json 형식의 configuration file은 다음과 같습니다.
```python
{
    "model" : {
        "min_input_size":       416,
        "max_input_size":       512,
        "anchors":              [4,21, 6,33, 10,48, 14,68, 20,99, 29,132, 38,191, 56,242, 87,324],
        "labels":               ["person"]
    },

    "train": {
        "train_image_folder":   "/home/Users/Desktop/Human_Detection/keras-yolov3-master/data/train/image/",
        "train_annot_folder":   "/home/Users/Desktop/Human_Detection/keras-yolov3-master/data/train/annot/",
        "cache_name":           "human_train.pkl",

        "train_times":          1,
        "batch_size":           4,
        "learning_rate":        1e-4,
        "nb_epochs":            50,
        "warmup_epochs":        3,
        "ignore_thresh":        0.5,
        "gpus":                 "1",

        "grid_scales":          [1,1,1],
        "obj_scale":            5,
        "noobj_scale":          1,
        "xywh_scale":           1,
        "class_scale":          1,

        "tensorboard_dir":      "log_human",
        "saved_weights_name":   "human.h5",
        "debug":                true
    },

    "valid": {
        "valid_image_folder":   "/home/Users/Desktop/Human_Detection/keras-yolov3-master/data/valid/image/",
        "valid_annot_folder":   "/home/Users/Desktop/Human_Detection/keras-yolov3-master/data/valid/annot/",
        "cache_name":           "human_valid.pkl",

        "valid_times":          1
    }
}
```
train/valid 폴더를 이전 단계에서 생성한 경로로 바꾸어줍니다.
saved_weights_name에 지정할 pre-trained 모델이 없을 경우 다음 링크에서 backend.h5 파일을 다운받아주세요.  
https://bit.ly/39rLNoE  

### 3. 데이터셋에 맞는 Anchor mask 생성하기 (선택사항)
```bash
python wagle.py --mode gen_anchor -a 9 -c json파일의_경로
```
클러스터링을 통해 학습할 이미지들의 크기에 맞는 Anchor값 9개를 출력합니다.  
config 파일의 ```anchors```부분에 복사하여 붙여놓으시면 됩니다.

### 4. 학습 시작하기
```bash
python wagle.py --model train -c json파일의_경로
```
가장 정확도가 높았던 best model이 ```saved_weights_name``` 부분에 적었던 이름으로 저장됩니다.  
valid 셋에 대해 loss가 3epoch동안 줄어들지 않으면 early stop합니다.


### 5. 로그 서버 동작시키기
```bash
python wagle_server.py
```
서버 역할을 할 컴퓨터에 해당 명령어를 입력하면 wait 상태가 되며 client의 통신을 기다립니다.  
client 서버에서 동영상 또는 웹캠의 수신이 시작되면, json 형태의 로그가 저장되어 해당 폴더에 생성되게 됩니다.
